{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d620b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/02/22 11:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from operator import add\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://192.168.2.70:7077\")\\\n",
    "        .appName(\"Jinglin_PartA\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\")\\\n",
    "        .config(\"spark.cores.max\", 4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")\n",
    "\n",
    "sc = SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cfbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1862234 lines in the English transcripts in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# QUESTION A.1 A1.1 Read the English transcripts, and count the number of lines\n",
    "corpus_en = spark_context.textFile('hdfs://192.168.2.70:9000/europarl/europarl-v7.sv-en.en')\n",
    "en_count = corpus_en.count()\n",
    "print(f'There are {en_count} lines in the English transcripts in total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61a63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1862234 lines in Swedish in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# QUESTION A.1 A1.2 Do the same with the other language\n",
    "corpus_sv = spark_context.textFile('hdfs://192.168.2.70:9000/europarl/europarl-v7.sv-en.sv')\n",
    "sv_count = corpus_sv.count()\n",
    "print(f'There are {sv_count} lines in Swedish in total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0e402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line counts are the same for the two languages\n"
     ]
    }
   ],
   "source": [
    "# QUESTION A.1 A1.3 Verify that the line counts are the same for the two languages.\n",
    "if en_count == sv_count:\n",
    "    print(\"The line counts are the same for the two languages\")\n",
    "else:\n",
    "    print(\"The line counts are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d13478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The partitions of English version:  2\n",
      "The partitions of Swedish version:  3\n"
     ]
    }
   ],
   "source": [
    "# QUESTION A.1 A1.4 Count the number of partitions\n",
    "partitions_en = corpus_en.getNumPartitions()\n",
    "partitions_sv = corpus_sv.getNumPartitions()\n",
    "print(\"The partitions of English version: \", partitions_en)\n",
    "print(\"The partitions of Swedish version: \", partitions_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe796203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION A.2 A2.1 Pre-process the text from both RDDs by doing the following:\n",
    "# Lowercase the text\n",
    "def to_lower(rdd):\n",
    "    return rdd.map(lambda x: x.lower())\n",
    "# rdd.map return a new RDD by applying a function to each element of this RDD\n",
    "corpus_enlower = to_lower(corpus_en)\n",
    "corpus_svlower = to_lower(corpus_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7389839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text(split on space)\n",
    "def split(corpus):\n",
    "    return corpus.map(lambda x: x.split(\" \"))\n",
    "\n",
    "corpus_enlowsp = split(corpus_enlower)\n",
    "corpus_svlowsp = split(corpus_svlower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1da7765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['återupptagande', 'av', 'sessionen'],\n",
       " ['jag',\n",
       "  'förklarar',\n",
       "  'europaparlamentets',\n",
       "  'session',\n",
       "  'återupptagen',\n",
       "  'efter',\n",
       "  'avbrottet',\n",
       "  'den',\n",
       "  '17',\n",
       "  'december.',\n",
       "  'jag',\n",
       "  'vill',\n",
       "  'på',\n",
       "  'nytt',\n",
       "  'önska',\n",
       "  'er',\n",
       "  'ett',\n",
       "  'gott',\n",
       "  'nytt',\n",
       "  'år',\n",
       "  'och',\n",
       "  'jag',\n",
       "  'hoppas',\n",
       "  'att',\n",
       "  'ni',\n",
       "  'haft',\n",
       "  'en',\n",
       "  'trevlig',\n",
       "  'semester.'],\n",
       " ['som',\n",
       "  'ni',\n",
       "  'kunnat',\n",
       "  'konstatera',\n",
       "  'ägde',\n",
       "  '\"den',\n",
       "  'stora',\n",
       "  'år',\n",
       "  '2000-buggen\"',\n",
       "  'aldrig',\n",
       "  'rum.',\n",
       "  'däremot',\n",
       "  'har',\n",
       "  'invånarna',\n",
       "  'i',\n",
       "  'ett',\n",
       "  'antal',\n",
       "  'av',\n",
       "  'våra',\n",
       "  'medlemsländer',\n",
       "  'drabbats',\n",
       "  'av',\n",
       "  'naturkatastrofer',\n",
       "  'som',\n",
       "  'verkligen',\n",
       "  'varit',\n",
       "  'förskräckliga.'],\n",
       " ['ni',\n",
       "  'har',\n",
       "  'begärt',\n",
       "  'en',\n",
       "  'debatt',\n",
       "  'i',\n",
       "  'ämnet',\n",
       "  'under',\n",
       "  'sammanträdesperiodens',\n",
       "  'kommande',\n",
       "  'dagar.'],\n",
       " ['till',\n",
       "  'dess',\n",
       "  'vill',\n",
       "  'jag',\n",
       "  'att',\n",
       "  'vi,',\n",
       "  'som',\n",
       "  'ett',\n",
       "  'antal',\n",
       "  'kolleger',\n",
       "  'begärt,',\n",
       "  'håller',\n",
       "  'en',\n",
       "  'tyst',\n",
       "  'minut',\n",
       "  'för',\n",
       "  'offren',\n",
       "  'för',\n",
       "  'bl.a.',\n",
       "  'stormarna',\n",
       "  'i',\n",
       "  'de',\n",
       "  'länder',\n",
       "  'i',\n",
       "  'europeiska',\n",
       "  'unionen',\n",
       "  'som',\n",
       "  'drabbats.'],\n",
       " ['jag', 'ber', 'er', 'resa', 'er', 'för', 'en', 'tyst', 'minut.'],\n",
       " ['(parlamentet', 'höll', 'en', 'tyst', 'minut.)'],\n",
       " ['fru', 'talman!', 'det', 'gäller', 'en', 'ordningsfråga.'],\n",
       " ['ni',\n",
       "  'känner',\n",
       "  'till',\n",
       "  'från',\n",
       "  'media',\n",
       "  'att',\n",
       "  'det',\n",
       "  'skett',\n",
       "  'en',\n",
       "  'rad',\n",
       "  'bombexplosioner',\n",
       "  'och',\n",
       "  'mord',\n",
       "  'i',\n",
       "  'sri',\n",
       "  'lanka.'],\n",
       " ['en',\n",
       "  'av',\n",
       "  'de',\n",
       "  'personer',\n",
       "  'som',\n",
       "  'mycket',\n",
       "  'nyligen',\n",
       "  'mördades',\n",
       "  'i',\n",
       "  'sri',\n",
       "  'lanka',\n",
       "  'var',\n",
       "  'kumar',\n",
       "  'ponnambalam,',\n",
       "  'som',\n",
       "  'besökte',\n",
       "  'europaparlamentet',\n",
       "  'för',\n",
       "  'bara',\n",
       "  'några',\n",
       "  'månader',\n",
       "  'sedan.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A2.2 Inspect 10 entries from each of your RDDs to verify pre-processing\n",
    "corpus_enlowsp.take(10)\n",
    "corpus_svlowsp.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717d2b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems ok.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Verify that the line counts still match after the pre-processing\n",
    "if corpus_enlowsp.count() == corpus_svlowsp.count():\n",
    "    print(\"It seems ok.\")\n",
    "else:\n",
    "    print(\"The lines are not match now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9407b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3498375, 'the'),\n",
       " (1659758, 'of'),\n",
       " (1539760, 'to'),\n",
       " (1288401, 'and'),\n",
       " (1085993, 'in'),\n",
       " (797516, 'that'),\n",
       " (773522, 'a'),\n",
       " (758050, 'is'),\n",
       " (534242, 'for'),\n",
       " (522849, 'we')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION A.3 A3.1 Use Spark to compute the 10 most frequently according words in the English language corpus.\n",
    "corpus_enflat = corpus_enlowsp.flatMap(lambda x: x)\n",
    "corpus_en_p = corpus_enflat.map(lambda x: (x,1))\n",
    "# corpus_wk = corpus_en_p.groupByKey()\n",
    "corpus_wordcount = corpus_en_p.reduceByKey(add)\n",
    "corpus_sort = corpus_wordcount.map(lambda pair: (pair[1], pair[0]))\n",
    "corpus_sort.sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed4508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1706293, 'att'),\n",
       " (1344830, 'och'),\n",
       " (1050774, 'i'),\n",
       " (924866, 'det'),\n",
       " (913276, 'som'),\n",
       " (908680, 'för'),\n",
       " (738068, 'av'),\n",
       " (694381, 'är'),\n",
       " (620310, 'en'),\n",
       " (539797, 'vi')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION A.3 A3.1 Repeat for swedish\n",
    "corpus_svflat = corpus_svlowsp.flatMap(lambda x: x)\n",
    "corpus_sv_p = corpus_svflat.map(lambda x: (x,1))\n",
    "corpus_svwordcount = corpus_sv_p.reduceByKey(add)\n",
    "corpus_svsort = corpus_svwordcount.map(lambda pair: (pair[1], pair[0]))\n",
    "corpus_svsort.sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff73709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3.2 Verify that results are reasonable.\n",
    "# Based on the information from internet, these words are the common words. Seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d85ae849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4780,\n",
       "  (['i',\n",
       "    'want',\n",
       "    'to',\n",
       "    'know',\n",
       "    'whether',\n",
       "    'this',\n",
       "    'also',\n",
       "    'applies',\n",
       "    'in',\n",
       "    'the',\n",
       "    'document',\n",
       "    'which',\n",
       "    'the',\n",
       "    'commission',\n",
       "    'has',\n",
       "    'presented',\n",
       "    'now.'],\n",
       "   ['jag',\n",
       "    'vill',\n",
       "    'veta',\n",
       "    'om',\n",
       "    'detta',\n",
       "    'också',\n",
       "    'gäller',\n",
       "    'i',\n",
       "    'det',\n",
       "    'dokument',\n",
       "    'som',\n",
       "    'kommissionen',\n",
       "    'har',\n",
       "    'presenterat',\n",
       "    'nu.']))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_en_zip = corpus_enlowsp.zipWithIndex()\n",
    "corpus_sv_zip = corpus_svlowsp.zipWithIndex()\n",
    "# swap the key and value so that the line number is the key.\n",
    "en_sw = corpus_en_zip.map(lambda pair: (pair[1], pair[0]))\n",
    "sv_sw = corpus_sv_zip.map(lambda pair: (pair[1], pair[0]))\n",
    "# join the two RDDs together\n",
    "corpus_join = en_sw.join(sv_sw)\n",
    "corpus_join.take(1)\n",
    "# filter_empty = corpus_join.filter(lambda pair: pair.isEmpty()==True)\n",
    "# filter_empty.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83db64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the empty/missing pairs\n",
    "filter_corpus = corpus_join.filter(lambda pair: len(pair[1][0])>0 and len(pair[1][1])>0)\n",
    "filter_corpus.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f443751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter to leave only pairs of sentences with a small number of words in each sentence.\n",
    "filter_short = filter_corpus.filter(lambda pair: len(pair[1][0])<10 or len(pair[1][1])<10)\n",
    "filter_sameshort = filter_short.filter(lambda pair: len(pair[1][0])==len(pair[1][1]))\n",
    "filter_sameshort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db767556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10040, ('is', 'är')),\n",
       " (5530, ('we', 'vi')),\n",
       " (5020, ('i', 'jag')),\n",
       " (3252, ('this', 'detta')),\n",
       " (2964, ('closed.', 'avslutad.')),\n",
       " (2917, ('and', 'och')),\n",
       " (2888, ('a', 'en')),\n",
       " (2866, ('it', 'det')),\n",
       " (2806, ('that', 'det')),\n",
       " (2650, ('not', 'inte'))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 48920)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For each sentence pair, map so that pair each(in order) word in the two sentences.\n",
    "def split_sentence(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "shortpairs = filter_sameshort.map(lambda pair: pair[1])\n",
    "wordpairs = shortpairs.map(lambda pair: list(zip(pair[0],pair[1]))).flatMap(lambda pairs: pairs)\n",
    "\n",
    "wordpairs_p = wordpairs.map(lambda pair: (pair, 1))\n",
    "wordpairs_count = wordpairs_p.reduceByKey(lambda a, b: a + b)\n",
    "pairsort = wordpairs_count.map(lambda pair: (pair[1], pair[0]))\n",
    "pairsort.sortByKey(False).take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result with dictionary:\n",
    "# is => är correct\n",
    "# we => vi correct\n",
    "# i => jag correct\n",
    "# this => datta correct\n",
    "# closed => avsluted incorrect\n",
    "# and => och correct\n",
    "# a => en correct\n",
    "# it => det correct\n",
    "# that => det correct\n",
    "# not => inte correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
